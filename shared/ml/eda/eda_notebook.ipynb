{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cac540e",
   "metadata": {},
   "source": [
    "# India AQI Prediction System - Exploratory Data Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook performs comprehensive exploratory data analysis on air quality data for India to understand patterns, trends, and relationships that will inform our prediction models.\n",
    "\n",
    "### Objectives:\n",
    "1. **Data Quality Assessment** - Missing values, outliers, data distribution\n",
    "2. **Temporal Analysis** - Time series patterns, seasonality, trends\n",
    "3. **Spatial Analysis** - Geographic distribution of pollution levels\n",
    "4. **Correlation Analysis** - Relationships between pollutants and weather\n",
    "5. **Feature Engineering Insights** - Identify important features for modeling\n",
    "\n",
    "### Data Sources:\n",
    "- Historical AQI data from major Indian cities\n",
    "- Weather data (temperature, humidity, wind, pressure)\n",
    "- Factory locations and emissions data\n",
    "- Forest cover data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e184c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import folium\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Analysis performed on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e490d",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f753ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic sample data for analysis\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample AQI data for major Indian cities\n",
    "cities = {\n",
    "    'Delhi': {'lat': 28.6139, 'lon': 77.2090, 'base_aqi': 180},\n",
    "    'Mumbai': {'lat': 19.0760, 'lon': 72.8777, 'base_aqi': 120},\n",
    "    'Bangalore': {'lat': 12.9716, 'lon': 77.5946, 'base_aqi': 85},\n",
    "    'Chennai': {'lat': 13.0827, 'lon': 80.2707, 'base_aqi': 95},\n",
    "    'Kolkata': {'lat': 22.5726, 'lon': 88.3639, 'base_aqi': 160},\n",
    "    'Hyderabad': {'lat': 17.3850, 'lon': 78.4867, 'base_aqi': 110},\n",
    "    'Pune': {'lat': 18.5204, 'lon': 73.8567, 'base_aqi': 100},\n",
    "    'Ahmedabad': {'lat': 23.0225, 'lon': 72.5714, 'base_aqi': 130}\n",
    "}\n",
    "\n",
    "# Generate 2 years of hourly data\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2024, 12, 31)\n",
    "date_range = pd.date_range(start_date, end_date, freq='H')\n",
    "\n",
    "data = []\n",
    "\n",
    "for timestamp in date_range:\n",
    "    for city, info in cities.items():\n",
    "        # Seasonal factors\n",
    "        month = timestamp.month\n",
    "        if month in [11, 12, 1]:  # Winter\n",
    "            seasonal_factor = 1.4\n",
    "        elif month in [4, 5]:  # Summer\n",
    "            seasonal_factor = 1.2\n",
    "        elif month in [6, 7, 8, 9]:  # Monsoon\n",
    "            seasonal_factor = 0.7\n",
    "        else:\n",
    "            seasonal_factor = 1.0\n",
    "        \n",
    "        # Hourly factors (rush hours effect)\n",
    "        hour = timestamp.hour\n",
    "        if hour in [7, 8, 9, 18, 19, 20]:  # Rush hours\n",
    "            hourly_factor = 1.3\n",
    "        elif hour in [10, 11, 14, 15]:  # Good dispersion\n",
    "            hourly_factor = 0.8\n",
    "        else:\n",
    "            hourly_factor = 1.0\n",
    "        \n",
    "        # Base AQI with variations\n",
    "        base_aqi = info['base_aqi']\n",
    "        aqi = base_aqi * seasonal_factor * hourly_factor + np.random.normal(0, 15)\n",
    "        aqi = max(10, min(500, aqi))\n",
    "        \n",
    "        # Generate related pollutants\n",
    "        pm25 = aqi * 0.4 + np.random.normal(0, 5)\n",
    "        pm10 = aqi * 0.6 + np.random.normal(0, 8)\n",
    "        no2 = 20 + (aqi / 10) + np.random.normal(0, 5)\n",
    "        o3 = 60 + (aqi / 8) + np.random.normal(0, 10)\n",
    "        so2 = 10 + (aqi / 15) + np.random.normal(0, 3)\n",
    "        co = 1 + (aqi / 100) + np.random.normal(0, 0.3)\n",
    "        \n",
    "        # Weather data\n",
    "        temp_base = 25 + (info['lat'] - 20) * -0.5 + 10 * np.cos(2 * np.pi * timestamp.dayofyear / 365)\n",
    "        temperature = temp_base + np.random.normal(0, 3)\n",
    "        humidity = 60 + 20 * np.sin(2 * np.pi * timestamp.dayofyear / 365) + np.random.normal(0, 10)\n",
    "        wind_speed = 3 + np.random.exponential(2)\n",
    "        pressure = 1013 + np.random.normal(0, 5)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'city': city,\n",
    "            'latitude': info['lat'],\n",
    "            'longitude': info['lon'],\n",
    "            'aqi': aqi,\n",
    "            'pm25': max(0, pm25),\n",
    "            'pm10': max(0, pm10),\n",
    "            'no2': max(0, no2),\n",
    "            'o3': max(0, o3),\n",
    "            'so2': max(0, so2),\n",
    "            'co': max(0, co),\n",
    "            'temperature': temperature,\n",
    "            'humidity': max(0, min(100, humidity)),\n",
    "            'wind_speed': max(0, wind_speed),\n",
    "            'pressure': pressure,\n",
    "            'month': month,\n",
    "            'hour': hour,\n",
    "            'day_of_week': timestamp.dayofweek,\n",
    "            'is_weekend': timestamp.dayofweek >= 5\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"Dataset created with {len(df):,} records\")\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"Cities: {df['city'].nunique()} - {list(df['city'].unique())}\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcbc80b",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(df.info())\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "print(\"\\n=== BASIC STATISTICS ===\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ab6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.isnull(), cbar=True, cmap='viridis', yticklabels=False)\n",
    "plt.title('Missing Values Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Records')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/missing_values_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Missing values heatmap saved to plots/missing_values_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41da1e71",
   "metadata": {},
   "source": [
    "## 3. AQI Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53edce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AQI distribution by city\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('AQI Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Overall AQI distribution\n",
    "axes[0, 0].hist(df['aqi'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Overall AQI Distribution')\n",
    "axes[0, 0].set_xlabel('AQI')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(df['aqi'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"aqi\"].mean():.1f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# AQI by city (box plot)\n",
    "df.boxplot(column='aqi', by='city', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('AQI Distribution by City')\n",
    "axes[0, 1].set_xlabel('City')\n",
    "axes[0, 1].set_ylabel('AQI')\n",
    "plt.setp(axes[0, 1].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# AQI categories distribution\n",
    "def get_aqi_category(aqi):\n",
    "    if aqi <= 50:\n",
    "        return 'Good'\n",
    "    elif aqi <= 100:\n",
    "        return 'Moderate'\n",
    "    elif aqi <= 150:\n",
    "        return 'Unhealthy for Sensitive'\n",
    "    elif aqi <= 200:\n",
    "        return 'Unhealthy'\n",
    "    elif aqi <= 300:\n",
    "        return 'Very Unhealthy'\n",
    "    else:\n",
    "        return 'Hazardous'\n",
    "\n",
    "df['aqi_category'] = df['aqi'].apply(get_aqi_category)\n",
    "category_counts = df['aqi_category'].value_counts()\n",
    "\n",
    "axes[1, 0].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "axes[1, 0].set_title('AQI Categories Distribution')\n",
    "\n",
    "# Top polluted cities (average AQI)\n",
    "city_avg_aqi = df.groupby('city')['aqi'].mean().sort_values(ascending=False)\n",
    "axes[1, 1].bar(city_avg_aqi.index, city_avg_aqi.values, color='coral')\n",
    "axes[1, 1].set_title('Average AQI by City')\n",
    "axes[1, 1].set_xlabel('City')\n",
    "axes[1, 1].set_ylabel('Average AQI')\n",
    "plt.setp(axes[1, 1].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/aqi_distribution_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ AQI distribution analysis saved to plots/aqi_distribution_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4c0bb",
   "metadata": {},
   "source": [
    "## 4. Temporal Patterns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c003ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series analysis\n",
    "fig, axes = plt.subplots(3, 2, figsize=(18, 15))\n",
    "fig.suptitle('Temporal Patterns in Air Quality', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Daily average AQI trend (sample period)\n",
    "daily_aqi = df.groupby(df['timestamp'].dt.date)['aqi'].mean()\n",
    "sample_period = daily_aqi.iloc[:90]  # First 90 days\n",
    "axes[0, 0].plot(sample_period.index, sample_period.values, linewidth=1, alpha=0.7)\n",
    "axes[0, 0].set_title('Daily AQI Trend (First 90 Days)')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Average AQI')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Monthly patterns\n",
    "monthly_aqi = df.groupby('month')['aqi'].mean()\n",
    "axes[0, 1].bar(monthly_aqi.index, monthly_aqi.values, color='lightcoral')\n",
    "axes[0, 1].set_title('Average AQI by Month')\n",
    "axes[0, 1].set_xlabel('Month')\n",
    "axes[0, 1].set_ylabel('Average AQI')\n",
    "axes[0, 1].set_xticks(range(1, 13))\n",
    "\n",
    "# Hourly patterns\n",
    "hourly_aqi = df.groupby('hour')['aqi'].mean()\n",
    "axes[1, 0].plot(hourly_aqi.index, hourly_aqi.values, marker='o', linewidth=2, color='green')\n",
    "axes[1, 0].set_title('Average AQI by Hour of Day')\n",
    "axes[1, 0].set_xlabel('Hour')\n",
    "axes[1, 0].set_ylabel('Average AQI')\n",
    "axes[1, 0].set_xticks(range(0, 24, 2))\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Day of week patterns\n",
    "dow_aqi = df.groupby('day_of_week')['aqi'].mean()\n",
    "dow_labels = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[1, 1].bar(range(7), dow_aqi.values, color='purple', alpha=0.7)\n",
    "axes[1, 1].set_title('Average AQI by Day of Week')\n",
    "axes[1, 1].set_xlabel('Day of Week')\n",
    "axes[1, 1].set_ylabel('Average AQI')\n",
    "axes[1, 1].set_xticks(range(7))\n",
    "axes[1, 1].set_xticklabels(dow_labels)\n",
    "\n",
    "# Weekend vs Weekday comparison\n",
    "weekend_comparison = df.groupby('is_weekend')['aqi'].mean()\n",
    "axes[2, 0].bar(['Weekday', 'Weekend'], weekend_comparison.values, color=['blue', 'orange'])\n",
    "axes[2, 0].set_title('Weekday vs Weekend AQI')\n",
    "axes[2, 0].set_ylabel('Average AQI')\n",
    "\n",
    "# Seasonal comparison\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8, 9]:\n",
    "        return 'Monsoon'\n",
    "    else:\n",
    "        return 'Post-Monsoon'\n",
    "\n",
    "df['season'] = df['month'].apply(get_season)\n",
    "seasonal_aqi = df.groupby('season')['aqi'].mean()\n",
    "axes[2, 1].bar(seasonal_aqi.index, seasonal_aqi.values, color=['brown', 'green', 'blue', 'orange'])\n",
    "axes[2, 1].set_title('Average AQI by Season')\n",
    "axes[2, 1].set_ylabel('Average AQI')\n",
    "plt.setp(axes[2, 1].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/temporal_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Temporal patterns analysis saved to plots/temporal_patterns.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4d2d3",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e98511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_features = ['aqi', 'pm25', 'pm10', 'no2', 'o3', 'so2', 'co', \n",
    "                       'temperature', 'humidity', 'wind_speed', 'pressure']\n",
    "\n",
    "correlation_matrix = df[correlation_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,\n",
    "            square=True, linewidths=0.5, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix: Pollutants and Weather Variables', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Correlation matrix saved to plots/correlation_matrix.png\")\n",
    "\n",
    "# Strong correlations summary\n",
    "print(\"\\n=== STRONG CORRELATIONS WITH AQI ===\")\n",
    "aqi_correlations = correlation_matrix['aqi'].abs().sort_values(ascending=False)\n",
    "print(aqi_correlations[aqi_correlations > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab07fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots for key relationships\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Key Relationships with AQI', fontsize=16, fontweight='bold')\n",
    "\n",
    "# AQI vs PM2.5\n",
    "axes[0, 0].scatter(df['pm25'], df['aqi'], alpha=0.5, color='red')\n",
    "axes[0, 0].set_xlabel('PM2.5 (Œºg/m¬≥)')\n",
    "axes[0, 0].set_ylabel('AQI')\n",
    "axes[0, 0].set_title('AQI vs PM2.5')\n",
    "\n",
    "# AQI vs Temperature\n",
    "axes[0, 1].scatter(df['temperature'], df['aqi'], alpha=0.5, color='orange')\n",
    "axes[0, 1].set_xlabel('Temperature (¬∞C)')\n",
    "axes[0, 1].set_ylabel('AQI')\n",
    "axes[0, 1].set_title('AQI vs Temperature')\n",
    "\n",
    "# AQI vs Wind Speed\n",
    "axes[0, 2].scatter(df['wind_speed'], df['aqi'], alpha=0.5, color='green')\n",
    "axes[0, 2].set_xlabel('Wind Speed (m/s)')\n",
    "axes[0, 2].set_ylabel('AQI')\n",
    "axes[0, 2].set_title('AQI vs Wind Speed')\n",
    "\n",
    "# AQI vs Humidity\n",
    "axes[1, 0].scatter(df['humidity'], df['aqi'], alpha=0.5, color='blue')\n",
    "axes[1, 0].set_xlabel('Humidity (%)')\n",
    "axes[1, 0].set_ylabel('AQI')\n",
    "axes[1, 0].set_title('AQI vs Humidity')\n",
    "\n",
    "# PM2.5 vs PM10\n",
    "axes[1, 1].scatter(df['pm25'], df['pm10'], alpha=0.5, color='purple')\n",
    "axes[1, 1].set_xlabel('PM2.5 (Œºg/m¬≥)')\n",
    "axes[1, 1].set_ylabel('PM10 (Œºg/m¬≥)')\n",
    "axes[1, 1].set_title('PM2.5 vs PM10')\n",
    "\n",
    "# NO2 vs AQI\n",
    "axes[1, 2].scatter(df['no2'], df['aqi'], alpha=0.5, color='brown')\n",
    "axes[1, 2].set_xlabel('NO2 (Œºg/m¬≥)')\n",
    "axes[1, 2].set_ylabel('AQI')\n",
    "axes[1, 2].set_title('AQI vs NO2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/scatter_relationships.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Scatter relationships saved to plots/scatter_relationships.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b263df",
   "metadata": {},
   "source": [
    "## 6. Spatial Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632afd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# City-wise AQI comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Spatial Distribution of Air Quality', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Average AQI by city\n",
    "city_stats = df.groupby('city').agg({\n",
    "    'aqi': ['mean', 'std', 'min', 'max'],\n",
    "    'pm25': 'mean',\n",
    "    'pm10': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "city_avg_aqi = df.groupby('city')['aqi'].mean().sort_values(ascending=True)\n",
    "axes[0, 0].barh(city_avg_aqi.index, city_avg_aqi.values, color='lightblue')\n",
    "axes[0, 0].set_title('Average AQI by City')\n",
    "axes[0, 0].set_xlabel('Average AQI')\n",
    "\n",
    "# AQI variability by city\n",
    "city_std_aqi = df.groupby('city')['aqi'].std().sort_values(ascending=True)\n",
    "axes[0, 1].barh(city_std_aqi.index, city_std_aqi.values, color='lightcoral')\n",
    "axes[0, 1].set_title('AQI Variability by City (Std Dev)')\n",
    "axes[0, 1].set_xlabel('AQI Standard Deviation')\n",
    "\n",
    "# PM2.5 vs PM10 by city\n",
    "city_pm = df.groupby('city')[['pm25', 'pm10']].mean()\n",
    "axes[1, 0].scatter(city_pm['pm25'], city_pm['pm10'], s=100, alpha=0.7)\n",
    "for i, city in enumerate(city_pm.index):\n",
    "    axes[1, 0].annotate(city, (city_pm['pm25'].iloc[i], city_pm['pm10'].iloc[i]), \n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "axes[1, 0].set_xlabel('Average PM2.5')\n",
    "axes[1, 0].set_ylabel('Average PM10')\n",
    "axes[1, 0].set_title('PM2.5 vs PM10 by City')\n",
    "\n",
    "# Worst air quality days by city\n",
    "worst_days = df[df['aqi'] > 200].groupby('city').size().sort_values(ascending=True)\n",
    "if len(worst_days) > 0:\n",
    "    axes[1, 1].barh(worst_days.index, worst_days.values, color='red', alpha=0.7)\n",
    "    axes[1, 1].set_title('Days with AQI > 200 by City')\n",
    "    axes[1, 1].set_xlabel('Number of Days')\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'No days with AQI > 200', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "    axes[1, 1].set_title('Days with AQI > 200 by City')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/spatial_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== CITY STATISTICS ===\")\n",
    "print(city_stats)\n",
    "print(\"\\n‚úÖ Spatial distribution analysis saved to plots/spatial_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive map with city AQI levels\n",
    "city_summary = df.groupby(['city', 'latitude', 'longitude']).agg({\n",
    "    'aqi': ['mean', 'max'],\n",
    "    'pm25': 'mean',\n",
    "    'pm10': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "city_summary.columns = ['avg_aqi', 'max_aqi', 'avg_pm25', 'avg_pm10']\n",
    "city_summary = city_summary.reset_index()\n",
    "\n",
    "# Create folium map\n",
    "m = folium.Map(location=[20.5937, 78.9629], zoom_start=5)\n",
    "\n",
    "for _, row in city_summary.iterrows():\n",
    "    # Color based on AQI level\n",
    "    if row['avg_aqi'] <= 50:\n",
    "        color = 'green'\n",
    "    elif row['avg_aqi'] <= 100:\n",
    "        color = 'yellow'\n",
    "    elif row['avg_aqi'] <= 150:\n",
    "        color = 'orange'\n",
    "    elif row['avg_aqi'] <= 200:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'purple'\n",
    "    \n",
    "    popup_text = f\"\"\"\n",
    "    <b>{row['city']}</b><br>\n",
    "    Avg AQI: {row['avg_aqi']:.1f}<br>\n",
    "    Max AQI: {row['max_aqi']:.1f}<br>\n",
    "    Avg PM2.5: {row['avg_pm25']:.1f} Œºg/m¬≥<br>\n",
    "    Avg PM10: {row['avg_pm10']:.1f} Œºg/m¬≥\n",
    "    \"\"\"\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=10,\n",
    "        popup=popup_text,\n",
    "        color='black',\n",
    "        fillColor=color,\n",
    "        fillOpacity=0.8,\n",
    "        weight=2\n",
    "    ).add_to(m)\n",
    "\n",
    "# Save map\n",
    "m.save('plots/aqi_spatial_map.html')\n",
    "print(\"‚úÖ Interactive AQI map saved to plots/aqi_spatial_map.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b68aa55",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for time series analysis\n",
    "print(\"=== FEATURE ENGINEERING ANALYSIS ===\")\n",
    "\n",
    "# Create sample lag features for one city\n",
    "delhi_data = df[df['city'] == 'Delhi'].copy().sort_values('timestamp')\n",
    "delhi_data['aqi_lag1'] = delhi_data['aqi'].shift(1)\n",
    "delhi_data['aqi_lag6'] = delhi_data['aqi'].shift(6)\n",
    "delhi_data['aqi_lag24'] = delhi_data['aqi'].shift(24)\n",
    "delhi_data['aqi_rolling_6h'] = delhi_data['aqi'].rolling(window=6).mean()\n",
    "delhi_data['aqi_rolling_24h'] = delhi_data['aqi'].rolling(window=24).mean()\n",
    "\n",
    "# Calculate correlations with current AQI\n",
    "lag_features = ['aqi_lag1', 'aqi_lag6', 'aqi_lag24', 'aqi_rolling_6h', 'aqi_rolling_24h']\n",
    "lag_correlations = delhi_data[['aqi'] + lag_features].corr()['aqi'].drop('aqi')\n",
    "\n",
    "print(\"\\nCorrelations between current AQI and lag features:\")\n",
    "print(lag_correlations.sort_values(ascending=False))\n",
    "\n",
    "# Feature importance simulation (using random forest)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare features for importance analysis\n",
    "feature_df = df.copy()\n",
    "le = LabelEncoder()\n",
    "feature_df['city_encoded'] = le.fit_transform(feature_df['city'])\n",
    "feature_df['season_encoded'] = le.fit_transform(feature_df['season'])\n",
    "\n",
    "feature_columns = ['pm25', 'pm10', 'no2', 'o3', 'so2', 'co', 'temperature', \n",
    "                  'humidity', 'wind_speed', 'pressure', 'month', 'hour', \n",
    "                  'day_of_week', 'city_encoded', 'season_encoded']\n",
    "\n",
    "X = feature_df[feature_columns]\n",
    "y = feature_df['aqi']\n",
    "\n",
    "# Fit random forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== FEATURE IMPORTANCE (Random Forest) ===\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be909c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=feature_importance.head(10), x='importance', y='feature', palette='viridis')\n",
    "plt.title('Top 10 Most Important Features for AQI Prediction', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Feature importance plot saved to plots/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183cec3",
   "metadata": {},
   "source": [
    "## 8. Summary and Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"              KEY INSIGHTS FROM EDA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüîç DATA QUALITY:\")\n",
    "print(f\"   ‚Ä¢ Dataset contains {len(df):,} records across {df['city'].nunique()} cities\")\n",
    "print(f\"   ‚Ä¢ Time period: {df['timestamp'].min().strftime('%Y-%m-%d')} to {df['timestamp'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   ‚Ä¢ No missing values detected\")\n",
    "print(f\"   ‚Ä¢ AQI range: {df['aqi'].min():.1f} to {df['aqi'].max():.1f}\")\n",
    "\n",
    "print(\"\\nüìä POLLUTION PATTERNS:\")\n",
    "most_polluted = df.groupby('city')['aqi'].mean().idxmax()\n",
    "least_polluted = df.groupby('city')['aqi'].mean().idxmin()\n",
    "print(f\"   ‚Ä¢ Most polluted city: {most_polluted} (avg AQI: {df.groupby('city')['aqi'].mean().max():.1f})\")\n",
    "print(f\"   ‚Ä¢ Least polluted city: {least_polluted} (avg AQI: {df.groupby('city')['aqi'].mean().min():.1f})\")\n",
    "\n",
    "worst_month = df.groupby('month')['aqi'].mean().idxmax()\n",
    "best_month = df.groupby('month')['aqi'].mean().idxmin()\n",
    "print(f\"   ‚Ä¢ Worst pollution month: {worst_month} (avg AQI: {df.groupby('month')['aqi'].mean().max():.1f})\")\n",
    "print(f\"   ‚Ä¢ Best pollution month: {best_month} (avg AQI: {df.groupby('month')['aqi'].mean().min():.1f})\")\n",
    "\n",
    "worst_hour = df.groupby('hour')['aqi'].mean().idxmax()\n",
    "best_hour = df.groupby('hour')['aqi'].mean().idxmin()\n",
    "print(f\"   ‚Ä¢ Peak pollution hour: {worst_hour}:00 (avg AQI: {df.groupby('hour')['aqi'].mean().max():.1f})\")\n",
    "print(f\"   ‚Ä¢ Lowest pollution hour: {best_hour}:00 (avg AQI: {df.groupby('hour')['aqi'].mean().min():.1f})\")\n",
    "\n",
    "print(\"\\nüîó CORRELATIONS:\")\n",
    "aqi_corr = df[['aqi', 'pm25', 'pm10', 'temperature', 'humidity', 'wind_speed']].corr()['aqi']\n",
    "strongest_positive = aqi_corr.drop('aqi').max()\n",
    "strongest_negative = aqi_corr.drop('aqi').min()\n",
    "print(f\"   ‚Ä¢ Strongest positive correlation: {aqi_corr.drop('aqi').idxmax()} (r={strongest_positive:.3f})\")\n",
    "print(f\"   ‚Ä¢ Strongest negative correlation: {aqi_corr.drop('aqi').idxmin()} (r={strongest_negative:.3f})\")\n",
    "\n",
    "print(\"\\nüèÜ TOP PREDICTIVE FEATURES:\")\n",
    "top_features = feature_importance.head(5)\n",
    "for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "    print(f\"   {i}. {row['feature']}: {row['importance']:.3f}\")\n",
    "\n",
    "print(\"\\nüìà SEASONAL INSIGHTS:\")\n",
    "seasonal_stats = df.groupby('season')['aqi'].agg(['mean', 'std']).round(1)\n",
    "for season, stats in seasonal_stats.iterrows():\n",
    "    print(f\"   ‚Ä¢ {season}: {stats['mean']} ¬± {stats['std']} AQI\")\n",
    "\n",
    "print(\"\\nüéØ MODELING RECOMMENDATIONS:\")\n",
    "print(\"   ‚Ä¢ Use PM2.5 and PM10 as primary features (strong correlation with AQI)\")\n",
    "print(\"   ‚Ä¢ Include temporal features (hour, month, season) for capturing patterns\")\n",
    "print(\"   ‚Ä¢ Consider lag features (previous hours) for time series modeling\")\n",
    "print(\"   ‚Ä¢ Weather features (wind speed, temperature) are important predictors\")\n",
    "print(\"   ‚Ä¢ City-specific models may perform better due to varying base pollution levels\")\n",
    "print(\"   ‚Ä¢ Focus on winter months and rush hours for critical pollution events\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810af93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary statistics to file\n",
    "summary_stats = {\n",
    "    'dataset_info': {\n",
    "        'total_records': len(df),\n",
    "        'cities': list(df['city'].unique()),\n",
    "        'date_range': f\"{df['timestamp'].min()} to {df['timestamp'].max()}\",\n",
    "        'aqi_range': f\"{df['aqi'].min():.1f} to {df['aqi'].max():.1f}\"\n",
    "    },\n",
    "    'city_rankings': {\n",
    "        'most_polluted': df.groupby('city')['aqi'].mean().sort_values(ascending=False).to_dict(),\n",
    "        'pollution_variability': df.groupby('city')['aqi'].std().sort_values(ascending=False).to_dict()\n",
    "    },\n",
    "    'temporal_patterns': {\n",
    "        'monthly_avg': df.groupby('month')['aqi'].mean().to_dict(),\n",
    "        'hourly_avg': df.groupby('hour')['aqi'].mean().to_dict(),\n",
    "        'seasonal_avg': df.groupby('season')['aqi'].mean().to_dict()\n",
    "    },\n",
    "    'correlations': df[['aqi', 'pm25', 'pm10', 'temperature', 'humidity', 'wind_speed']].corr()['aqi'].to_dict(),\n",
    "    'feature_importance': feature_importance.set_index('feature')['importance'].to_dict()\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('eda_summary.json', 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2, default=str)\n",
    "\n",
    "print(\"‚úÖ EDA summary saved to eda_summary.json\")\n",
    "print(\"‚úÖ All plots saved to plots/ directory\")\n",
    "print(\"\\nüéâ Exploratory Data Analysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
